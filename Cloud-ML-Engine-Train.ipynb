{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/food_model; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "  # copy canonical set of preprocessed files if you didn't do previous notebook\n",
    "  gsutil -m cp -R gs://food_model gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/food_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "grep \"^def\" food_model/food_nodfood.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf \n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "#Data reading and preprocessing function\n",
    "def imgs_input_fn(path, mode, batch_size=15):\n",
    "    imagepaths, imagelabels = [], []\n",
    "    \n",
    "    #List the directory\n",
    "    classes = os.walk(path).__next__()[1]\n",
    "    label = 0\n",
    "    buffer_size = 0\n",
    "    #List each sub-directory (the classes)\n",
    "    for c in classes:\n",
    "        c_dir = os.path.join(path,c)\n",
    "        img_paths = os.walk(c_dir).__next__()[2]\n",
    "    \n",
    "        #Add each image to training set\n",
    "        for image_path in img_paths:\n",
    "            imagepaths.append(os.path.join(c_dir,image_path))\n",
    "            imagelabels.append(label)\n",
    "            buffer_size += 1\n",
    "            \n",
    "        label += 1\n",
    "   \n",
    "    imagepaths = tf.constant(imagepaths)\n",
    "    imagelabels = tf.constant(imagelabels)\n",
    "    \n",
    "    def _parse_function(file, label):\n",
    "        image_string = tf.read_file(file)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string)\n",
    "        image_resized = tf.image.resize_images(image_decoded,[244,244])\n",
    "        image_resized.set_shape([244, 244, 3])\n",
    "        \n",
    "        return image_resized, label\n",
    "    \n",
    "    def augment(image, label):\n",
    "        augment_image = tf.random_crop(image, [244,244,3])\n",
    "        augment_image = tf.image.random_flip_left_right(image)\n",
    "        augment_image = tf.contrib.image.rotate(augment_image, 50)\n",
    "        \n",
    "        return augment_image, label\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((imagepaths,imagelabels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    \n",
    "    #Create batches \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None\n",
    "        dataset = dataset.map(augment)\n",
    "        dataset = dataset.repeat(num_epochs).shuffle(buffer_size=buffer_size)\n",
    "    else:\n",
    "        num_epochs = 1\n",
    "    \n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)    \n",
    "    iterator = dataset.make_one_shot_iterator() \n",
    "    features, labels = iterator.get_next()\n",
    "    labels = tf.reshape(labels,[-1, 1])\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(2)\n",
    "    np.random.seed(2)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1 , 244, 244, 3])\n",
    "    \n",
    "    #Convolutional and Pooling layers\n",
    "    conv1 = tf.layers.conv2d(input_layer, 16, 3, activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(pool1, 32, 3, activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(pool2, 64, 3, activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, 2, 2)\n",
    "    \n",
    "    #Dense layer\n",
    "    flat = tf.contrib.layers.flatten(pool3)\n",
    "    dense = tf.layers.dense(flat, 64, activation=tf.nn.relu)\n",
    "    drop = tf.layers.dropout(dense, rate=0.3, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #Logits layer\n",
    "    logits = tf.layers.dense(drop, 2)\n",
    "    \n",
    "    #Generate predictions\n",
    "    predictions = {\"classes\": tf.argmax(input=logits, axis=1),\"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")}\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    #Calculate Loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "    \n",
    "    #Configure the Training Op\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op) \n",
    "    \n",
    "    #Add evaluation metrics\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "#food_classifier = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir='food_model')\n",
    "eval_int = 50\n",
    "\n",
    "food_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir='gs://BUCKET/food_model/food_notfood_trained',\n",
    "                                        config=tf.estimator.RunConfig(save_checkpoints_secs=eval_int))  \n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn= lambda: imgs_input_fn(\"gs://BuCKET/food_model/train\", mode=tf.estimator.ModeKeys.TRAIN), max_steps=60)\n",
    "\n",
    "#exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn= lambda: imgs_input_fn(\"gs://BUCKET/food_model/test\", mode=tf.estimator.ModeKeys.EVAL),\n",
    "                                   start_delay_secs=eval_int, throttle_secs=eval_int)\n",
    "    \n",
    "tf.estimator.train_and_evaluate(food_classifier, train_spec, eval_spec)\n",
    "\n",
    "\n",
    "#Pred data reading and preprocessing function\n",
    "#def img_input_fn(path):\n",
    "#    imagepaths = []\n",
    "#    \n",
    "#    images = os.walk(path).__next__()[2]\n",
    "#    for img in images:\n",
    "#        img_path = os.path.join(path,img)\n",
    "#        imagepaths.append(img_path)\n",
    "#       \n",
    "#    imagepaths = tf.constant(imagepaths)\n",
    "#    \n",
    "#    def _parse_function(file):\n",
    "#        image_string = tf.read_file(file)\n",
    "#        image_decoded = tf.image.decode_jpeg(image_string)\n",
    "#        image_resized = tf.image.resize_images(image_decoded,[244,244])\n",
    "#        image_resized.set_shape([244, 244, 3])\n",
    "#        return image_resized\n",
    "#    \n",
    "#    dataset = tf.data.Dataset.from_tensor_slices(imagepaths)\n",
    "#    dataset = dataset.map(_parse_function)\n",
    "#    \n",
    "#    iterator = dataset.make_one_shot_iterator() \n",
    "#    features = iterator.get_next()\n",
    "#    \n",
    "#    return features\n",
    "\n",
    "#pred = food_classifier.predict(input_fn=lambda: img_input_fn(\"n\"))\n",
    "\n",
    "#for prediction in pred:\n",
    "   \n",
    "#    if prediction[\"classes\"] == 0:\n",
    "#        print(\"Food\")\n",
    "#    else:\n",
    "#        print(\"Not Food\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf food-model\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/food_model\n",
    "python -m food_model.food_notfood \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --output_dir=food_model/food_notfood_trained \\\n",
    "  --job-dir=./tmp \\\n",
    "  # --train_examples=1 --eval_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/food_model/food_notfood_trained\n",
    "JOBNAME=food_model_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=food_model.food_notfood \\\n",
    "  --package-path=$(pwd)/food_model \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  #--bucket=${BUCKET} \\\n",
    "  #--output_dir=${OUTDIR} \\\n",
    "  #--train_examples=200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./food_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
